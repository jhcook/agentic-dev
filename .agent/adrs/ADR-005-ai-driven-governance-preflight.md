# ADR-005: AI-Driven Governance Preflight

## Status
Accepted

## Context
As the codebase grows, manual code review becomes a bottleneck. Furthermore, specific domains like Security, Compliance (SOC2), and Architecture require specialized knowledge that not every human reviewer possesses.  In an agentic workflow, we need to ensure that code generated by agents (or humans) satisfies these multi-disciplinary constraints *before* it is merged.

Relying solely on human review for these checks is:
1. **Slow**: Blocks high-velocity agentic workflows.
2. **Inconsistent**: Humans might miss a subtle PII leak or architectural violation.
3. **Expensive**: Requires high-level intervention for every PR.

## Decision
We will implement an **AI-Driven Preflight Governance Council** that runs as a CLI command (`agent preflight`).

### 1. The Persona Model
We define specific "Virtual Agents" or roles in `agents.yaml` (e.g., `@Security`, `@Architect`, `@Compliance`). Each role has:
- **Focus Area**: A specific definition of what they care about (e.g., "PII leaks", "Dependency hygiene").
- **Authority**: The ability to `BLOCK` a change if it violates their constraints.

### 2. The Preflight Workflow
The `agent preflight` command executes the following process:
1. **Diff Extraction**: Captures the staged git diff.
2. **Context Assembly**: Loads the relevant Story, Governance Rules, and Role Instructions.
3. **Parallel Evaluation**: Instantiates an LLM session for each relevant role (Parallel or Sequential depending on API limits).
   - Each role is prompted: "You are @Security. Review this diff against these rules. PASS or BLOCK?".
4. **Aggregation**: If *any* role returns a `BLOCK` verdict, the entire preflight fails.
5. **Reporting**: Generates a detailed audit log (`.agent/logs/`) explaining who blocked it and why.

### 3. Integration
- **Local**: Developers run `agent preflight` before committing.
- **CI/CD**: GitHub Actions runs `agent preflight` on every PR. If it fails, the build fails.

## Consequences

### Positive
1. **Scalable Governance**: We can add new compliance rules (e.g., "No new Python 2 code") simply by updating the `@Architect` instructions, without retraining humans.
2. **Immediate Feedback**: Developers get detailed feedback in seconds, not hours/days.
3. **Audit Trail**: Every change has a machine-generated compliance report associated with it.

### Negative
1. **False Positives**: LLMs may flag innocent code as violations (e.g., flagging a variable named `password_hash` in a test file as a leak).
2. **Cost/Latency**: Running 5-10 concurrent LLM calls per commit can be slow and incur API costs.
3. **Determinism Issues**: LLMs might give different verdicts on the same code (Mitigation: Use low temperature).
